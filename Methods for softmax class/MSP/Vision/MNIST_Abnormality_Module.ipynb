{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "from load_cifar10 import load_data10\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "# training parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 30\n",
    "batch_size = 128\n",
    "\n",
    "# architecture parameters\n",
    "n_labels = 10\n",
    "image_pixels = 28 * 28\n",
    "bottleneck = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_noise(batch, complexity=0.5):\n",
    "    return batch + np.random.normal(size=batch.shape, scale=1e-9 + complexity)\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "def blur(img, complexity=0.5):\n",
    "    image = img.reshape((-1, 28, 28))\n",
    "    return gaussian(image, sigma=5*complexity).reshape((-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(dtype=tf.float32, shape=[None, image_pixels])\n",
    "    y = tf.placeholder(dtype=tf.int64, shape=[None])\n",
    "    risk_labels = tf.placeholder(dtype=tf.float32, shape=[None])\n",
    "    is_unfrozen = tf.placeholder(tf.bool)\n",
    "\n",
    "\n",
    "    def gelu_fast(x):\n",
    "        return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "    rho = gelu_fast\n",
    "\n",
    "    # if mode == 'input_restricted':\n",
    "    W = {}\n",
    "    b = {}\n",
    "\n",
    "    with tf.variable_scope(\"in_sample\"):\n",
    "        W['1'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([image_pixels, 256]), 0))\n",
    "        W['2'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, 256]), 0))\n",
    "        W['3'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, 256]), 0))\n",
    "        W['logits'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, n_labels]), 0))\n",
    "        W['bottleneck'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, bottleneck]), 0))\n",
    "        W['decode1'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([bottleneck, 256]), 0))\n",
    "        W['decode2'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, 256]), 0))\n",
    "        W['reconstruction'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, image_pixels]), 0))\n",
    "\n",
    "        b['1'] = tf.Variable(tf.zeros([256]))\n",
    "        b['2'] = tf.Variable(tf.zeros([256]))\n",
    "        b['3'] = tf.Variable(tf.zeros([256]))\n",
    "        b['logits'] = tf.Variable(tf.zeros([n_labels]))\n",
    "        b['bottleneck'] = tf.Variable(tf.zeros([bottleneck]))\n",
    "        b['decode1'] = tf.Variable(tf.zeros([256]))\n",
    "        b['decode2'] = tf.Variable(tf.zeros([256]))\n",
    "        b['reconstruction'] = tf.Variable(tf.zeros([image_pixels]))\n",
    "\n",
    "    with tf.variable_scope(\"out_of_sample\"):\n",
    "        W['residual_to_risk1'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([image_pixels, 512]), 0))\n",
    "        W['hidden_to_risk1'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([256, 512]), 0))\n",
    "        W['logits_to_risk1'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([n_labels, 512]), 0))\n",
    "        W['risk2'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([512, 128]), 0))\n",
    "        W['risk'] = tf.Variable(tf.nn.l2_normalize(tf.random_normal([128, 1]), 0))\n",
    "\n",
    "        b['risk1'] = tf.Variable(tf.zeros([512]))\n",
    "        b['risk2'] = tf.Variable(tf.zeros([128]))\n",
    "        b['risk'] = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "    def risk_net(x):\n",
    "        h1 = rho(tf.matmul(x, W['1']) + b['1'])\n",
    "        h2 = rho(tf.matmul(h1, W['2']) + b['2'])\n",
    "        h3 = rho(tf.matmul(h2, W['3']) + b['3'])\n",
    "        logits_out = tf.matmul(h3, W['logits']) + b['logits']\n",
    "\n",
    "        hidden_to_bottleneck = rho(tf.matmul(h2, W['bottleneck']) + b['bottleneck'])\n",
    "        d1 = rho(tf.matmul(hidden_to_bottleneck, W['decode1']) + b['decode1'])\n",
    "        d2 = rho(tf.matmul(d1, W['decode2']) + b['decode2'])\n",
    "        recreation = tf.matmul(d2, W['reconstruction']) + b['reconstruction']\n",
    "\n",
    "        risk1 = rho(tf.matmul(logits_out, W['logits_to_risk1']) +\n",
    "                    tf.matmul(tf.square(x - recreation), W['residual_to_risk1']) +\n",
    "                    tf.matmul(h2, W['hidden_to_risk1']) + b['risk1'])\n",
    "        risk2 = rho(tf.matmul(risk1, W['risk2']) + b['risk2'])\n",
    "        risk_out = tf.matmul(risk2, W['risk'])\n",
    "\n",
    "        return logits_out, recreation, tf.squeeze(risk_out)\n",
    "\n",
    "    logits, reconstruction, risk = risk_net(x)\n",
    "    ce = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))\n",
    "    rec_error = tf.reduce_mean(tf.square(x - reconstruction))\n",
    "    loss = 0.9 * ce + 0.1 * rec_error\n",
    "    lr = tf.constant(0.001)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss)\n",
    "    \n",
    "    compute_error = 100*tf.reduce_mean(tf.to_float(tf.not_equal(tf.argmax(logits, 1), y)))\n",
    "    compute_risk_error = 100*tf.reduce_mean(tf.to_float(tf.not_equal(tf.to_int64(tf.round(tf.sigmoid(risk))),\n",
    "                                                                     tf.to_int64(tf.round(risk_labels)))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training: Phase 1\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(graph=graph)\n",
    "print('Beginning training: Phase 1')\n",
    "\n",
    "# Adam requires special care\n",
    "in_sample_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"in_sample\")\n",
    "out_of_sample_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"out_of_sample\")\n",
    "sess.run(tf.initialize_variables(set(tf.all_variables()) - set(out_of_sample_vars)))\n",
    "\n",
    "num_batches = int(mnist.train.num_examples / batch_size)\n",
    "save_every = int(num_batches/3.1)      # save training information 3 times per epoch\n",
    "ce_ema = 2.3            # - log(0.1)\n",
    "err_ema = 0.9\n",
    "risk_loss_ema = 0.3     # - log(0.5)\n",
    "learning_rate = 0.001\n",
    "for epoch in range(training_epochs):\n",
    "    if epoch >= 20:\n",
    "        learning_rate = 0.0001\n",
    "    for i in range(num_batches):\n",
    "        bx, by = mnist.train.next_batch(batch_size)\n",
    "        _, err, l = sess.run([optimizer, compute_error, ce], feed_dict={x: bx, y: by, is_unfrozen: True,\n",
    "                                                                        lr: learning_rate})\n",
    "        ce_ema = ce_ema * 0.95 + 0.05 * l\n",
    "        err_ema = err_ema * 0.95 + 0.05 * err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering out-of-distribution training phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/Software/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:162: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  return self._images[start:end], self._labels[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | ema of risk for epoch: 0.0289991779286 error (%): 1.02815375856\n",
      "Epoch: 1 | ema of risk for epoch: 0.0235179694132 error (%): 0.796505824561\n",
      "Epoch: 2 | ema of risk for epoch: 0.0173152953255 error (%): 0.727457317635\n",
      "Epoch: 3 | ema of risk for epoch: 0.0137615267565 error (%): 0.513664685183\n",
      "Epoch: 4 | ema of risk for epoch: 0.0132930072201 error (%): 0.45190325967\n",
      "Epoch: 5 | ema of risk for epoch: 0.0176867936823 error (%): 0.733053278535\n",
      "Epoch: 6 | ema of risk for epoch: 0.0082577667913 error (%): 0.248823425983\n",
      "Epoch: 7 | ema of risk for epoch: 0.0105122508973 error (%): 0.283814799134\n",
      "Epoch: 8 | ema of risk for epoch: 0.011084522913 error (%): 0.449430105553\n",
      "Epoch: 9 | ema of risk for epoch: 0.0104165609187 error (%): 0.342036450263\n",
      "Epoch: 10 | ema of risk for epoch: 0.00670572366864 error (%): 0.227839521794\n",
      "Epoch: 11 | ema of risk for epoch: 0.00618380575562 error (%): 0.24187715303\n",
      "Epoch: 12 | ema of risk for epoch: 0.00836288376746 error (%): 0.214100012671\n",
      "Epoch: 13 | ema of risk for epoch: 0.0107128988622 error (%): 0.329135162083\n",
      "Epoch: 14 | ema of risk for epoch: 0.00716427481169 error (%): 0.237637717177\n"
     ]
    }
   ],
   "source": [
    "print('Entering out-of-distribution training phase')\n",
    "\n",
    "# Adam requires special care\n",
    "risk_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(risk, risk_labels))\n",
    "phase2_vars = list(set(tf.all_variables()) - set(in_sample_vars))\n",
    "curr_lr = learning_rate\n",
    "risk_optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(risk_loss, var_list=phase2_vars)\n",
    "sess.run(tf.initialize_variables(set(tf.all_variables()) - set(in_sample_vars)))\n",
    "\n",
    "err_ema = 50\n",
    "for epoch in range(15):\n",
    "    for i in range(num_batches):\n",
    "        offset = i * batch_size\n",
    "        bx, by = mnist.train.next_batch(1.5*batch_size)\n",
    "\n",
    "        bx1 = bx[0:batch_size//6]\n",
    "        bx2 = mnist.validation.next_batch(batch_size//3)[0][batch_size//6:batch_size//3]\n",
    "        distortion = np.random.uniform(low=0.9, high=1.2)\n",
    "        bx3 = add_noise(bx[batch_size//3:4*batch_size//6], complexity=distortion)\n",
    "        distortion = np.random.uniform(low=0.9, high=1)\n",
    "        bx4 = blur(bx[4*batch_size//6:5*batch_size//6], complexity=distortion)\n",
    "        bx5 = np.zeros(shape=(batch_size - 5*batch_size//6, 28*28))\n",
    "        for k in range(5*batch_size//6, batch_size):\n",
    "            if by[k] == 0:\n",
    "                bx5[k - 5*batch_size//6] = add_noise(bx[k], complexity=1).reshape((28*28,))\n",
    "            else:\n",
    "                bx5[k - 5*batch_size//6] = np.rot90(bx[k].reshape((28,28)),\n",
    "                                                    k=np.random.choice([1,3])).reshape((28*28,))\n",
    "        risks = np.zeros(batch_size)\n",
    "        risks[:batch_size//3] = 1\n",
    "        bx = np.vstack((bx1, bx2, bx3, bx4, bx5))\n",
    "\n",
    "        _, rl, err = sess.run([risk_optimizer, risk_loss, compute_risk_error],\n",
    "                              feed_dict={x: bx, risk_labels: risks, is_unfrozen: False})\n",
    "        risk_loss_ema = risk_loss_ema * 0.95 + 0.05 * rl\n",
    "        err_ema = err_ema * 0.95 + 0.05 * err\n",
    "\n",
    "    print('Epoch:', epoch, '|', 'ema of risk for epoch:', risk_loss_ema, 'error (%):', err_ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load notMNIST, CIFAR-10, and Omniglot\n",
    "pickle_file = './data/notMNIST.pickle'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f, encoding='latin1')\n",
    "    notmnist_dataset = save['test_dataset'].reshape((-1, 28 * 28))\n",
    "    del save\n",
    "\n",
    "_, _, X_test, _ = load_data10()\n",
    "cifar_batch = sess.run(tf.image.resize_images(tf.image.rgb_to_grayscale(X_test), 28, 28))\n",
    "\n",
    "import scipy.io as sio\n",
    "import scipy.misc as scimisc\n",
    "# other alphabets have characters which overlap\n",
    "safe_list = [0,2,5,6,8,12,13,14,15,16,17,18,19,21,26]\n",
    "m = sio.loadmat(\"./data/data_background.mat\")\n",
    "\n",
    "squished_set = []\n",
    "for safe_number in safe_list:\n",
    "    for alphabet in m['images'][safe_number]:\n",
    "        for letters in alphabet:\n",
    "            for letter in letters:\n",
    "                for example in letter:\n",
    "                    squished_set.append(scimisc.imresize(1 - example[0], (28,28)).reshape(1, 28*28))\n",
    "\n",
    "omni_images = np.concatenate(squished_set, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST Digit Error (%) | MNIST Riskiness Error (%) | Digit Confidence (mean, std):\n",
      "1.46 | 1.07 | 0.995995 0.0350266\n"
     ]
    }
   ],
   "source": [
    "err, r_err, r, conf  = sess.run([compute_error, compute_risk_error, tf.sigmoid(risk), tf.nn.softmax(logits)],\n",
    "                          feed_dict={x: mnist.test.images, y: mnist.test.labels, risk_labels: np.ones(10000)})\n",
    "\n",
    "r_right = r[np.argmax(conf, axis=1).astype(np.uint8) == mnist.test.labels]\n",
    "\n",
    "print('MNIST Digit Error (%) | MNIST Riskiness Error (%) | Digit Confidence (mean, std):')\n",
    "print(err, '|', r_err, '|', np.mean(np.max(conf, axis=1)), np.std(np.max(conf, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = tf.nn.softmax(logits)\n",
    "s_prob = tf.reduce_max(s, reduction_indices=[1], keep_dims=True)\n",
    "kl_all = tf.log(10.) + tf.reduce_sum(s * tf.log(tf.abs(s) + 1e-11), reduction_indices=[1], keep_dims=True)\n",
    "m_all, v_all = tf.nn.moments(kl_all, axes=[0])\n",
    "\n",
    "logits_right = tf.boolean_mask(logits, tf.equal(tf.argmax(logits, 1), y))\n",
    "s_right = tf.nn.softmax(logits_right)\n",
    "s_right_prob = tf.reduce_max(s_right, reduction_indices=[1], keep_dims=True)\n",
    "kl_right = tf.log(10.) + tf.reduce_sum(s_right * tf.log(tf.abs(s_right) + 1e-11),\n",
    "                                       reduction_indices=[1], keep_dims=True)\n",
    "m_right, v_right = tf.nn.moments(kl_right, axes=[0])\n",
    "\n",
    "logits_wrong = tf.boolean_mask(logits, tf.not_equal(tf.argmax(logits, 1), y))\n",
    "s_wrong = tf.nn.softmax(logits_wrong)\n",
    "s_wrong_prob = tf.reduce_max(s_wrong, reduction_indices=[1], keep_dims=True)\n",
    "kl_wrong = tf.log(10.) + tf.reduce_sum(s_wrong * tf.log(tf.abs(s_wrong) + 1e-11),\n",
    "                                       reduction_indices=[1], keep_dims=True)\n",
    "m_wrong, v_wrong = tf.nn.moments(kl_wrong, axes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Success Detection\n",
      "Success base rate (%): 98.54\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 99.96\n",
      "AUROC (%): 97.45\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 99.95\n",
      "AUROC (%): 96.67\n",
      "\n",
      "Error Detection\n",
      "Error base rate (%): 1.46\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 39.21\n",
      "AUROC (%): 97.45\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 39.33\n",
      "AUROC (%): 96.67\n"
     ]
    }
   ],
   "source": [
    "kl_a, kl_r, kl_w, s_p, s_rp, s_wp = sess.run(\n",
    "    [kl_all, kl_right, kl_wrong, s_prob, s_right_prob, s_wrong_prob],\n",
    "    feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
    "\n",
    "print('\\nSuccess Detection')\n",
    "print('Success base rate (%):', round(100-err,2))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "safe, risky = kl_r, kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = s_rp, s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "print('\\nError Detection')\n",
    "print('Error base rate (%):', round(err,2))\n",
    "safe, risky = -kl_r, -kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = -s_rp, -s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_ood_detection_results_softmax(error_rate_for_in, in_examples, out_examples):\n",
    "    kl_oos, s_p_oos = sess.run([kl_all, s_prob], feed_dict={x: out_examples})\n",
    "\n",
    "    print('OOD Example Prediction Probability (mean, std):')\n",
    "    print(np.mean(s_p_oos), np.std(s_p_oos))\n",
    "\n",
    "    print('\\nNormality Detection')\n",
    "    print('Normality base rate (%):', round(100*in_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection')\n",
    "    safe, risky = kl_a, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection')\n",
    "    safe, risky = s_p, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Normality base rate (%):', round(100*(1 - err/100)*in_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = kl_r, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = s_rp, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "    print('\\n\\nAbnormality Detection')\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Abnormality Detection')\n",
    "    safe, risky = -kl_a, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Abnormality Detection')\n",
    "    safe, risky = -s_p, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Abnormality Detection (relative to correct examples)')\n",
    "    safe, risky = -kl_r, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Abnormality Detection (relative to correct examples)')\n",
    "    safe, risky = -s_rp, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omniglot (Softmax version)\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.878658 0.174975\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 52.08\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 95.47\n",
      "AUROC (%): 94.75\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 95.01\n",
      "AUROC (%): 94.12\n",
      "Normality base rate (%): 51.72\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 95.85\n",
      "AUROC (%): 95.43\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 95.39\n",
      "AUROC (%): 94.81\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 47.92\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 93.89\n",
      "AUROC (%): 94.75\n",
      "Prediction Prob: Abnormality Detection\n",
      "AUPR (%): 93.39\n",
      "AUROC (%): 94.12\n",
      "Abnormality base rate (%): 48.28\n",
      "KL[p||u]: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 95.2\n",
      "AUROC (%): 95.43\n",
      "Prediction Prob: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 94.83\n",
      "AUROC (%): 94.81\n"
     ]
    }
   ],
   "source": [
    "print('Omniglot (Softmax version)\\n')\n",
    "show_ood_detection_results_softmax(err, mnist.test.images, omni_images.reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notMNIST (Softmax version)\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.917525 0.14954\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 87.12\n",
      "AUROC (%): 86.69\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 87.5\n",
      "AUROC (%): 86.1\n",
      "Normality base rate (%): 49.63\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 87.49\n",
      "AUROC (%): 87.44\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 87.87\n",
      "AUROC (%): 86.85\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 88.22\n",
      "AUROC (%): 86.69\n",
      "Prediction Prob: Abnormality Detection\n",
      "AUPR (%): 88.01\n",
      "AUROC (%): 86.1\n",
      "Abnormality base rate (%): 50.37\n",
      "KL[p||u]: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 89.77\n",
      "AUROC (%): 87.44\n",
      "Prediction Prob: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 89.67\n",
      "AUROC (%): 86.85\n"
     ]
    }
   ],
   "source": [
    "print('notMNIST (Softmax version)\\n')\n",
    "show_ood_detection_results_softmax(err, mnist.test.images, notmnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10bw (Softmax Version)\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.792851 0.217157\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 97.77\n",
      "AUROC (%): 97.54\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 97.57\n",
      "AUROC (%): 97.26\n",
      "Normality base rate (%): 49.63\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 98.09\n",
      "AUROC (%): 98.02\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 97.91\n",
      "AUROC (%): 97.78\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 97.35\n",
      "AUROC (%): 97.54\n",
      "Prediction Prob: Abnormality Detection\n",
      "AUPR (%): 96.96\n",
      "AUROC (%): 97.26\n",
      "Abnormality base rate (%): 50.37\n",
      "KL[p||u]: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 98.04\n",
      "AUROC (%): 98.02\n",
      "Prediction Prob: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 97.81\n",
      "AUROC (%): 97.78\n"
     ]
    }
   ],
   "source": [
    "print('CIFAR-10bw (Softmax Version)\\n')\n",
    "show_ood_detection_results_softmax(err, mnist.test.images, cifar_batch.reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheer White Gaussian Noise (Softmax Version)\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.925578 0.13632\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 87.93\n",
      "AUROC (%): 87.52\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 88.06\n",
      "AUROC (%): 86.78\n",
      "Normality base rate (%): 49.63\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 88.32\n",
      "AUROC (%): 88.29\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 88.45\n",
      "AUROC (%): 87.54\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 88.46\n",
      "AUROC (%): 87.52\n",
      "Prediction Prob: Abnormality Detection\n",
      "AUPR (%): 88.21\n",
      "AUROC (%): 86.78\n",
      "Abnormality base rate (%): 50.37\n",
      "KL[p||u]: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 90.15\n",
      "AUROC (%): 88.29\n",
      "Prediction Prob: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 89.97\n",
      "AUROC (%): 87.54\n"
     ]
    }
   ],
   "source": [
    "print('Sheer White Gaussian Noise (Softmax Version)\\n')\n",
    "show_ood_detection_results_softmax(err, mnist.test.images, np.random.normal(size=(10000, 28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheer Uniform Noise (Softmax Version)\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.706721 0.229194\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 99.36\n",
      "AUROC (%): 99.19\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 99.27\n",
      "AUROC (%): 99.02\n",
      "Normality base rate (%): 49.63\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.57\n",
      "AUROC (%): 99.48\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.51\n",
      "AUROC (%): 99.37\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 99.03\n",
      "AUROC (%): 99.19\n",
      "Prediction Prob: Abnormality Detection\n",
      "AUPR (%): 98.68\n",
      "AUROC (%): 99.02\n",
      "Abnormality base rate (%): 50.37\n",
      "KL[p||u]: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 99.41\n",
      "AUROC (%): 99.48\n",
      "Prediction Prob: Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 99.22\n",
      "AUROC (%): 99.37\n"
     ]
    }
   ],
   "source": [
    "print('Sheer Uniform Noise (Softmax Version)\\n')\n",
    "show_ood_detection_results_softmax(err, mnist.test.images, np.random.uniform(size=(10000, 28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_ood_detection_results(error_rate_for_in, in_examples, out_examples):\n",
    "    r_oos, conf = sess.run([tf.sigmoid(risk), tf.nn.softmax(logits)], feed_dict={x: out_examples})\n",
    "    \n",
    "    print('OOD Example Prediction Probability (mean, std):')\n",
    "    print(np.mean(np.max(conf, axis=1)), np.std(np.max(conf, axis=1)))\n",
    "\n",
    "    print('\\nNormality Detection')\n",
    "    print('Normality base rate (%):', round(100*in_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('Normality Detection')\n",
    "    safe, risky = r.reshape(-1,1), r_oos.reshape(-1, 1)\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Normality base rate (%):', round(100*(1 - err/100)*in_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('Normality Detection (relative to correct examples)')\n",
    "    safe, risky = r_right.reshape(-1,1), r_oos.reshape(-1, 1)\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('\\n\\nAbnormality Detection')\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('Abnormality Detection')\n",
    "    safe, risky = 1 - r.reshape(-1,1), 1 - r_oos.reshape(-1, 1)\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('Abnormality Detection (relative to correct examples)')\n",
    "    safe, risky = 1 - r_right.reshape(-1,1), 1 - r_oos.reshape(-1, 1)\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Omniglot\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.878658 0.174975\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 52.08\n",
      "Normality Detection\n",
      "AUPR (%): 99.56\n",
      "AUROC (%): 99.5\n",
      "Normality base rate (%): 51.72\n",
      "Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.62\n",
      "AUROC (%): 99.59\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 47.92\n",
      "Abnormality Detection\n",
      "AUPR (%): 99.45\n",
      "AUROC (%): 99.5\n",
      "Abnormality base rate (%): 48.28\n",
      "Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 99.57\n",
      "AUROC (%): 99.59\n"
     ]
    }
   ],
   "source": [
    "print('Omniglot\\n')\n",
    "show_ood_detection_results(err, mnist.test.images, omni_images.reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notMNIST\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.917525 0.14954\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "Normality Detection\n",
      "AUPR (%): 99.99\n",
      "AUROC (%): 99.99\n",
      "Normality base rate (%): 49.63\n",
      "Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.99\n",
      "AUROC (%): 99.99\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "Abnormality Detection\n",
      "AUPR (%): 99.99\n",
      "AUROC (%): 99.99\n",
      "Abnormality base rate (%): 50.37\n",
      "Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 99.99\n",
      "AUROC (%): 99.99\n"
     ]
    }
   ],
   "source": [
    "print('notMNIST\\n')\n",
    "show_ood_detection_results(err, mnist.test.images, notmnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIFAR-10bw\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.792851 0.217157\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "Normality Detection\n",
      "AUPR (%): 99.93\n",
      "AUROC (%): 99.93\n",
      "Normality base rate (%): 49.63\n",
      "Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.95\n",
      "AUROC (%): 99.95\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "Abnormality Detection\n",
      "AUPR (%): 99.93\n",
      "AUROC (%): 99.93\n",
      "Abnormality base rate (%): 50.37\n",
      "Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 99.95\n",
      "AUROC (%): 99.95\n"
     ]
    }
   ],
   "source": [
    "print('CIFAR-10bw\\n')\n",
    "show_ood_detection_results(err, mnist.test.images, cifar_batch.reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheer White Gaussian Noise\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.920849 0.144049\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "Normality Detection\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "Normality base rate (%): 49.63\n",
      "Normality Detection (relative to correct examples)\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "Abnormality Detection\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "Abnormality base rate (%): 50.37\n",
      "Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n"
     ]
    }
   ],
   "source": [
    "print('Sheer White Gaussian Noise\\n')\n",
    "show_ood_detection_results(err, mnist.test.images, np.random.normal(size=(10000, 28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheer Uniform Noise\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.707209 0.228498\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 50.0\n",
      "Normality Detection\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "Normality base rate (%): 49.63\n",
      "Normality Detection (relative to correct examples)\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 50.0\n",
      "Abnormality Detection\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n",
      "Abnormality base rate (%): 50.37\n",
      "Abnormality Detection (relative to correct examples)\n",
      "AUPR (%): 100.0\n",
      "AUROC (%): 100.0\n"
     ]
    }
   ],
   "source": [
    "print('Sheer Uniform Noise\\n')\n",
    "show_ood_detection_results(err, mnist.test.images, np.random.uniform(size=(10000, 28*28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import sklearn.metrics as sk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename='./data/imdb.train'):\n",
    "    '''\n",
    "    :param filename: the system location of the data to load\n",
    "    :return: the text (x) and its label (y)\n",
    "             the text is a list of words and is not processed\n",
    "    '''\n",
    "\n",
    "    # stop words taken from nltk\n",
    "    stop_words = ['i','me','my','myself','we','our','ours','ourselves','you','your','yours',\n",
    "                  'yourself','yourselves','he','him','his','himself','she','her','hers','herself',\n",
    "                  'it','its','itself','they','them','their','theirs','themselves','what','which',\n",
    "                  'who','whom','this','that','these','those','am','is','are','was','were','be',\n",
    "                  'been','being','have','has','had','having','do','does','did','doing','a','an',\n",
    "                  'the','and','but','if','or','because','as','until','while','of','at','by','for',\n",
    "                  'with','about','against','between','into','through','during','before','after',\n",
    "                  'above','below','to','from','up','down','in','out','on','off','over','under',\n",
    "                  'again','further','then','once','here','there','when','where','why','how','all',\n",
    "                  'any','both','each','few','more','most','other','some','such','no','nor','not',\n",
    "                  'only','own','same','so','than','too','very','s','t','can','will','just','don',\n",
    "                  'should','now','d','ll','m','o','re','ve','y','ain','aren','couldn','didn',\n",
    "                  'doesn','hadn','hasn','haven','isn','ma','mightn','mustn','needn','shan',\n",
    "                  'shouldn','wasn','weren','won','wouldn']\n",
    "\n",
    "    x, y = [], []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = re.sub(r'\\W+', ' ', line).strip().lower()  # perhaps don't make words lowercase?\n",
    "            x.append(line[:-1])\n",
    "            x[-1] = ' '.join(word for word in x[-1].split() if word not in stop_words)\n",
    "            y.append(line[-1])\n",
    "    return x, np.array(y, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(dataset):\n",
    "    '''\n",
    "    :param dataset: the text from load_data\n",
    "\n",
    "    :return: a _ordered_ dictionary from words to counts\n",
    "    '''\n",
    "    vocab = {}\n",
    "\n",
    "    # create a counter for each word\n",
    "    for example in dataset:\n",
    "        example_as_list = example.split()\n",
    "        for word in example_as_list:\n",
    "            vocab[word] = 0\n",
    "\n",
    "    for example in dataset:\n",
    "        example_as_list = example.split()\n",
    "        for word in example_as_list:\n",
    "            vocab[word] += 1\n",
    "    \n",
    "    # sort from greatest to least by count\n",
    "    return collections.OrderedDict(sorted(vocab.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_rank(dataset, _vocab, desired_vocab_size=5000):\n",
    "    '''\n",
    "    :param dataset: the text from load_data\n",
    "    :vocab: a _ordered_ dictionary of vocab words and counts from get_vocab\n",
    "    :param desired_vocab_size: the desired vocabulary size\n",
    "    words no longer in vocab become UUUNNNKKK\n",
    "    :return: the text corpus with words mapped to their vocab rank,\n",
    "    with all sufficiently infrequent words mapped to UUUNNNKKK; UUUNNNKKK has rank desired_vocab_size\n",
    "    (the infrequent word cutoff is determined by desired_vocab size)\n",
    "    '''\n",
    "    _dataset = dataset[:]     # aliasing safeguard\n",
    "    vocab_ordered = list(_vocab)\n",
    "    count_cutoff = _vocab[vocab_ordered[desired_vocab_size-1]] # get word by its rank and map to its count\n",
    "    \n",
    "    word_to_rank = {}\n",
    "    for i in range(len(vocab_ordered)):\n",
    "        # we add one to make room for any future padding symbol with value 0\n",
    "        word_to_rank[vocab_ordered[i]] = i + 1\n",
    "    \n",
    "    # we need to ensure that other words below the word on the edge of our desired_vocab size\n",
    "    # are not also on the count cutoff, so we subtract a bit\n",
    "    # this is likely quicker than adding another preventative if case\n",
    "    for i in range(50):\n",
    "        _vocab[vocab_ordered[desired_vocab_size+i]] -= 0.1\n",
    "    \n",
    "    for i in range(len(_dataset)):\n",
    "        example = _dataset[i]\n",
    "        example_as_list = example.split()\n",
    "        for j in range(len(example_as_list)):\n",
    "            try:\n",
    "                if _vocab[example_as_list[j]] >= count_cutoff:\n",
    "                    example_as_list[j] = word_to_rank[example_as_list[j]] \n",
    "                else:\n",
    "                    example_as_list[j] = desired_vocab_size  # UUUNNNKKK\n",
    "            except:\n",
    "                example_as_list[j] = desired_vocab_size  # UUUNNNKKK\n",
    "        _dataset[i] = example_as_list\n",
    "\n",
    "    return _dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# taken from keras\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32',\n",
    "                  padding='pre', truncating='pre', value=0.):\n",
    "    '''Pads each sequence to the same length:\n",
    "    the length of the longest sequence.\n",
    "    If maxlen is provided, any sequence longer\n",
    "    than maxlen is truncated to maxlen.\n",
    "    Truncation happens off either the beginning (default) or\n",
    "    the end of the sequence.\n",
    "    Supports post-padding and pre-padding (default).\n",
    "    # Arguments\n",
    "        sequences: list of lists where each element is a sequence\n",
    "        maxlen: int, maximum length\n",
    "        dtype: type to cast the resulting sequence.\n",
    "        padding: 'pre' or 'post', pad either before or after each sequence.\n",
    "        truncating: 'pre' or 'post', remove values from sequences larger than\n",
    "            maxlen either in the beginning or in the end of the sequence\n",
    "        value: float, value to pad the sequences to the desired value.\n",
    "    # Returns\n",
    "        x: numpy array with dimensions (number_of_sequences, maxlen)\n",
    "    '''\n",
    "    lengths = [len(s) for s in sequences]\n",
    "\n",
    "    nb_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((nb_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if len(s) == 0:\n",
    "            continue  # empty list was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "max_example_len = 400\n",
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "vocab_size = 5000\n",
    "num_epochs = 15\n",
    "\n",
    "print('Loading Data')\n",
    "X_train, Y_train = load_data()\n",
    "X_dev, Y_dev = load_data('./data/imdb.dev')\n",
    "X_test, Y_test = load_data('./data/imdb.test')\n",
    "\n",
    "vocab = get_vocab(X_train)\n",
    "X_train = text_to_rank(X_train, vocab, 5000)\n",
    "X_dev = text_to_rank(X_dev, vocab, 5000)\n",
    "X_test = text_to_rank(X_test, vocab, 5000)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_example_len)\n",
    "X_dev = pad_sequences(X_dev, maxlen=max_example_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_example_len)\n",
    "print('Data loaded')\n",
    "\n",
    "num_examples = Y_train.shape[0]\n",
    "num_batches = num_examples//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(dtype=tf.int32, shape=[None, max_example_len])\n",
    "    y = tf.placeholder(dtype=tf.int64, shape=[None])\n",
    "#     is_training = tf.placeholder(tf.bool)\n",
    "    \n",
    "    # add one to vocab size for the padding symbol\n",
    "    W_embedding = tf.Variable(tf.nn.l2_normalize(\n",
    "        tf.random_normal([vocab_size+1, embedding_dims]), 0), trainable=True)\n",
    "    \n",
    "    w_vecs = tf.nn.embedding_lookup(W_embedding, x)\n",
    "    pooled = tf.reduce_mean(w_vecs, reduction_indices=[1])\n",
    "    \n",
    "    W_out = tf.Variable(tf.nn.l2_normalize(tf.random_normal([embedding_dims, 2]), 0))\n",
    "    b_out = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "    logits = tf.matmul(pooled, W_out) + b_out\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(loss)\n",
    "\n",
    "    acc = 100*tf.reduce_mean(tf.to_float(tf.equal(tf.argmax(logits, 1), y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.InteractiveSession(graph=graph)\n",
    "tf.initialize_all_variables().run()\n",
    "# create saver to train model\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "\n",
    "print('Initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Minibatch loss 0.457 | Minibatch accuracy 84.375 | Dev accuracy 78.460\n",
      "Epoch 2 | Minibatch loss 0.369 | Minibatch accuracy 84.375 | Dev accuracy 85.320\n",
      "Epoch 3 | Minibatch loss 0.277 | Minibatch accuracy 90.625 | Dev accuracy 88.060\n",
      "Epoch 4 | Minibatch loss 0.220 | Minibatch accuracy 87.500 | Dev accuracy 87.660\n",
      "Epoch 5 | Minibatch loss 0.197 | Minibatch accuracy 96.875 | Dev accuracy 82.460\n",
      "Epoch 6 | Minibatch loss 0.194 | Minibatch accuracy 93.750 | Dev accuracy 86.120\n",
      "Epoch 7 | Minibatch loss 0.208 | Minibatch accuracy 96.875 | Dev accuracy 88.060\n",
      "Epoch 8 | Minibatch loss 0.188 | Minibatch accuracy 90.625 | Dev accuracy 88.680\n",
      "Epoch 9 | Minibatch loss 0.347 | Minibatch accuracy 87.500 | Dev accuracy 85.920\n",
      "Epoch 10 | Minibatch loss 0.403 | Minibatch accuracy 78.125 | Dev accuracy 89.340\n",
      "Epoch 11 | Minibatch loss 0.170 | Minibatch accuracy 96.875 | Dev accuracy 84.740\n",
      "Epoch 12 | Minibatch loss 0.110 | Minibatch accuracy 96.875 | Dev accuracy 88.740\n",
      "Epoch 13 | Minibatch loss 0.116 | Minibatch accuracy 93.750 | Dev accuracy 84.560\n",
      "Epoch 14 | Minibatch loss 0.278 | Minibatch accuracy 81.250 | Dev accuracy 87.660\n",
      "Epoch 15 | Minibatch loss 0.139 | Minibatch accuracy 100.000 | Dev accuracy 88.520\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # shuffle data every epoch\n",
    "    indices = np.arange(num_examples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    Y_train = Y_train[indices]\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        offset = i * batch_size\n",
    "\n",
    "        x_batch = X_train[offset:offset + batch_size]\n",
    "        y_batch = Y_train[offset:offset + batch_size]\n",
    "\n",
    "        _, l, batch_acc = sess.run([optimizer, loss, acc], feed_dict={x: x_batch, y: y_batch})\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            curr_dev_acc = sess.run(\n",
    "                acc, feed_dict={x: X_dev, y: Y_dev})\n",
    "            if best_acc < curr_dev_acc:\n",
    "                best_acc = curr_dev_acc\n",
    "                saver.save(sess, './data/best_imdb_model.ckpt')\n",
    "\n",
    "    print('Epoch %d | Minibatch loss %.3f | Minibatch accuracy %.3f | Dev accuracy %.3f' %\n",
    "          (epoch+1, l, batch_acc, curr_dev_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model restored!\n",
      "Dev accuracy: 89.34\n"
     ]
    }
   ],
   "source": [
    "# restore variables from disk\n",
    "saver.restore(sess, \"./data/best_imdb_model.ckpt\")\n",
    "print(\"Best model restored!\")\n",
    "\n",
    "print('Dev accuracy:', sess.run(acc, feed_dict={x: X_dev, y: Y_dev}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = tf.nn.softmax(logits)\n",
    "s_prob = tf.reduce_max(s, reduction_indices=[1], keep_dims=True)\n",
    "kl_all = tf.log(2.) + tf.reduce_sum(s * tf.log(tf.abs(s) + 1e-10), reduction_indices=[1], keep_dims=True)\n",
    "m_all, v_all = tf.nn.moments(kl_all, axes=[0])\n",
    "\n",
    "logits_right = tf.boolean_mask(logits, tf.equal(tf.argmax(logits, 1), y))\n",
    "s_right = tf.nn.softmax(logits_right)\n",
    "s_right_prob = tf.reduce_max(s_right, reduction_indices=[1], keep_dims=True)\n",
    "kl_right = tf.log(2.) + tf.reduce_sum(s_right * tf.log(tf.abs(s_right) + 1e-10), reduction_indices=[1], keep_dims=True)\n",
    "m_right, v_right = tf.nn.moments(kl_right, axes=[0])\n",
    "\n",
    "logits_wrong = tf.boolean_mask(logits, tf.not_equal(tf.argmax(logits, 1), y))\n",
    "s_wrong = tf.nn.softmax(logits_wrong)\n",
    "s_wrong_prob = tf.reduce_max(s_wrong, reduction_indices=[1], keep_dims=True)\n",
    "kl_wrong = tf.log(2.) + tf.reduce_sum(s_wrong * tf.log(tf.abs(s_wrong) + 1e-10), reduction_indices=[1], keep_dims=True)\n",
    "m_wrong, v_wrong = tf.nn.moments(kl_wrong, axes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Error (%)| Prediction Prob (mean, std) | PProb Right (mean, std) | PProb Wrong (mean, std):\n",
      "11.792 | 0.888981 0.137194 | 0.909461 0.121211 | 0.735784 0.152013\n",
      "\n",
      "Success Detection\n",
      "Success base rate (%): 88.21\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 96.86\n",
      "AUROC (%): 82.04\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 96.86\n",
      "AUROC (%): 82.04\n",
      "\n",
      "Error Detection\n",
      "Error base rate (%): 11.79\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 36.56\n",
      "AUROC (%): 82.04\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 36.53\n",
      "AUROC (%): 82.04\n"
     ]
    }
   ],
   "source": [
    "err, kl_a, kl_r, kl_w, s_p, s_rp, s_wp = sess.run(\n",
    "    [100 - acc, kl_all, kl_right, kl_wrong, s_prob, s_right_prob, s_wrong_prob],\n",
    "    feed_dict={x: X_test, y: Y_test})\n",
    "\n",
    "print('IMDB Error (%)| Prediction Prob (mean, std) | PProb Right (mean, std) | PProb Wrong (mean, std):')\n",
    "print(err, '|', np.mean(s_p), np.std(s_p), '|', np.mean(s_rp), np.std(s_rp), '|', np.mean(s_wp), np.std(s_wp))\n",
    "\n",
    "print('\\nSuccess Detection')\n",
    "print('Success base rate (%):', round(100-err,2))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "safe, risky = kl_r, kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = s_rp, s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "print('\\nError Detection')\n",
    "print('Error base rate (%):', round(err,2))\n",
    "safe, risky = -kl_r, -kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = -s_rp, -s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_ood_detection_results(error_rate_for_in, in_examples, out_examples):\n",
    "    kl_oos, s_p_oos = sess.run([kl_all, s_prob], feed_dict={x: out_examples})\n",
    "\n",
    "    print('OOD Example Prediction Probability (mean, std):')\n",
    "    print(np.mean(s_p_oos), np.std(s_p_oos))\n",
    "\n",
    "    print('\\nNormality Detection')\n",
    "    print('Normality base rate (%):', round(100*in_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection')\n",
    "    safe, risky = kl_a, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection')\n",
    "    safe, risky = s_p, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Normality base rate (%):', round(100*(1 - err/100)*in_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = kl_r, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = s_rp, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "    print('\\n\\nAbnormality Detection')\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Abnormality Detection')\n",
    "    safe, risky = -kl_a, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection')\n",
    "    safe, risky = -s_p, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = -kl_r, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = -s_rp, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cr_data, cr_labels = load_data('./data/CR.train')\n",
    "cr_data = text_to_rank(cr_data, vocab, 5000)\n",
    "cr_data = pad_sequences(cr_data, maxlen=max_example_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Reviews\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.607808 0.0847973\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 90.01\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 99.17\n",
      "AUROC (%): 92.67\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 99.17\n",
      "AUROC (%): 92.67\n",
      "Normality base rate (%): 88.82\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.38\n",
      "AUROC (%): 95.08\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 99.38\n",
      "AUROC (%): 95.08\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 9.99\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 47.29\n",
      "AUROC (%): 92.67\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 47.27\n",
      "AUROC (%): 92.67\n",
      "Abnormality base rate (%): 11.18\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 61.77\n",
      "AUROC (%): 95.08\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 61.75\n",
      "AUROC (%): 95.08\n"
     ]
    }
   ],
   "source": [
    "print('Customer Reviews\\n')\n",
    "show_ood_detection_results(err, X_test, cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt_data, rt_labels = load_data('./data/MR.train')\n",
    "rt_data = text_to_rank(rt_data, vocab, 5000)\n",
    "rt_data = pad_sequences(rt_data, maxlen=max_example_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Reviews\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.62482 0.095235\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 74.27\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 97.2\n",
      "AUROC (%): 91.29\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 97.2\n",
      "AUROC (%): 91.29\n",
      "Normality base rate (%): 71.8\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 97.85\n",
      "AUROC (%): 93.99\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 97.85\n",
      "AUROC (%): 93.99\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 25.73\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 69.74\n",
      "AUROC (%): 91.29\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 69.72\n",
      "AUROC (%): 91.29\n",
      "Abnormality base rate (%): 28.2\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 80.17\n",
      "AUROC (%): 93.99\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 80.15\n",
      "AUROC (%): 93.99\n"
     ]
    }
   ],
   "source": [
    "print('Movie Reviews\\n')\n",
    "show_ood_detection_results(err, X_test, rt_data)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

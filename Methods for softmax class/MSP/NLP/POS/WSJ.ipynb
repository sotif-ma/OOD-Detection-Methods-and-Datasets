{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import collections\n",
    "import sklearn.metrics as sk\n",
    "from helper_functions_wsj import *\n",
    "from glob import glob\n",
    "from reader import Reader\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading WSJ Data\n",
      "extended [('**start**', 'START'), ('It', 'PRP'), ('has', 'VBZ'), ('no', 'DT'), ('bearing', 'NN'), ('on', 'IN'), ('our', 'PRP$'), ('work', 'NN'), ('force', 'NN'), ('today', 'NN'), ('.', '.'), (\"''\", \"''\"), ('**end**', 'END')]\n",
      "extended [('**start**', 'START'), ('He', 'PRP'), ('predicted', 'VBD'), ('the', 'DT'), ('problem', 'NN'), ('will', 'MD'), ('be', 'VB'), ('solved', 'VBN'), ('``', '``'), ('very', 'RB'), ('soon', 'RB'), ('.', '.'), (\"''\", \"''\"), ('**end**', 'END')]\n",
      "pad all sentences to 36\n",
      "Loaded WSJ Data\n"
     ]
    }
   ],
   "source": [
    "print('Loading WSJ Data')\n",
    "reader = Reader(split=0.9)\n",
    "(X_train, Y_train, mask_train,\n",
    " X_test, Y_test, mask_test) = \\\n",
    "    reader.get_data(glob('./data/WSJ/*/*.POS'))\n",
    "print('Loaded WSJ Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    batch_size = 32\n",
    "    hidden_size = 128\n",
    "    num_layers = 3\n",
    "    vocab_size = len(reader.word_to_id)\n",
    "    tag_size = len(reader.tag_to_id)\n",
    "    maxlen = reader.maxlen\n",
    "\n",
    "    input_data = tf.placeholder(tf.int64, [None, maxlen])\n",
    "    targets = tf.placeholder(tf.int64, [None, maxlen])\n",
    "    mask = tf.placeholder(tf.bool, [None, maxlen])\n",
    "\n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(hidden_size, state_is_tuple=True)\n",
    "    # if is_training and dropout_keep_prob < 1:\n",
    "    #     lstm_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "    #         lstm_cell, output_keep_prob=dropout_keep_prob)\n",
    "\n",
    "    cell_fw = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "    cell_bw = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * num_layers, state_is_tuple=True)\n",
    "\n",
    "    initial_state_fw = cell_fw.zero_state(tf.shape(input_data)[0], tf.float32)\n",
    "    initial_state_bw = cell_bw.zero_state(tf.shape(input_data)[0], tf.float32)\n",
    "\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        embedding = tf.get_variable(\"embedding\", [vocab_size,\n",
    "                                                  hidden_size])\n",
    "        inputs = tf.nn.embedding_lookup(embedding, input_data)\n",
    "\n",
    "    inputs = [input_ for input_ in tf.unpack(tf.transpose(inputs, [1, 0, 2]))]\n",
    "    # if is_training and dropout_keep_prob < 1:\n",
    "    #     inputs = tf.nn.dropout(tf.pack(inputs), dropout_keep_prob)\n",
    "    #     inputs = tf.unpack(inputs)\n",
    "    outputs, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, inputs,\n",
    "                                            initial_state_fw=initial_state_fw,\n",
    "                                            initial_state_bw=initial_state_bw)\n",
    "\n",
    "    # output from forward and backward cells.\n",
    "    output = tf.reshape(tf.concat(1, outputs), [-1, 2 * hidden_size])\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [2 * hidden_size, tag_size])\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [tag_size])\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    loss = tf.nn.seq2seq.sequence_loss_by_example(\n",
    "        [logits], [tf.reshape(targets, [-1])],\n",
    "        [tf.reshape(tf.cast(mask, tf.float32), [-1])], tag_size)\n",
    "    cost = tf.reduce_sum(loss) / batch_size\n",
    "\n",
    "    equality = tf.equal(tf.argmax(logits, 1),\n",
    "                        tf.cast(tf.reshape(targets, [-1]), tf.int64))\n",
    "    masked = tf.boolean_mask(equality, tf.reshape(mask, [-1]))\n",
    "    misclass = 1 - tf.reduce_mean(tf.cast(masked, tf.float32))\n",
    "\n",
    "    lr = tf.Variable(0.0, trainable=False)\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), 5.0)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_op = optimizer.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "def assign_lr(session, lr_value):\n",
    "    session.run(tf.assign(lr, lr_value))\n",
    "    \n",
    "def run_epoch(x_data, y_data, data_mask, eval_op, training=True, verbose=False):\n",
    "    \"\"\"Runs the model on the given data.\"\"\"\n",
    "    epoch_size = ((len(x_data) // batch_size) - 1)\n",
    "    start_time = time.time()\n",
    "    costs = 0.0\n",
    "    iters = 0\n",
    "    misclass_ = []\n",
    "    for step, (x, y, data_mask) in enumerate(Reader.iterator(x_data, y_data, data_mask, batch_size)):\n",
    "        if training is True:\n",
    "            l, misclassifications, _ = sess.run([cost, misclass, eval_op],\n",
    "                                                   {input_data: x, targets: y, mask: data_mask})\n",
    "        else:\n",
    "            l, misclassifications = sess.run([cost, misclass],\n",
    "                                                {input_data: x, targets: y, mask: data_mask})\n",
    "        costs += l\n",
    "        iters += batch_size\n",
    "\n",
    "        if verbose and step % (epoch_size // 10) == 0:\n",
    "            print(\"[%s] %.3f perplexity: %.3f misclass:%.3f speed: %.0f wps\" %\n",
    "                  ('train' if training else 'test', step * 1.0 / epoch_size,\n",
    "                   np.exp(costs / iters), misclassifications,\n",
    "                   iters * batch_size / (time.time() - start_time)))\n",
    "        misclass_.append(misclassifications)\n",
    "    return np.exp(costs / iters), np.mean(misclass_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession(graph=graph)\n",
    "tf.initialize_all_variables().run()\n",
    "print('Initialized')\n",
    "\n",
    "# create saver for model\n",
    "saver = tf.train.Saver(max_to_keep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Learning rate: 1.000\n",
      "[train] 0.000 perplexity: 7.755 misclass:0.998 speed: 930 wps\n",
      "[train] 0.100 perplexity: 5.157 misclass:0.822 speed: 7597 wps\n",
      "[train] 0.200 perplexity: 4.398 misclass:0.717 speed: 7752 wps\n",
      "[train] 0.299 perplexity: 3.409 misclass:0.341 speed: 7802 wps\n",
      "[train] 0.399 perplexity: 2.744 misclass:0.169 speed: 7831 wps\n",
      "[train] 0.499 perplexity: 2.332 misclass:0.090 speed: 7828 wps\n",
      "[train] 0.599 perplexity: 2.079 misclass:0.065 speed: 7838 wps\n",
      "[train] 0.699 perplexity: 1.906 misclass:0.049 speed: 7848 wps\n",
      "[train] 0.799 perplexity: 1.783 misclass:0.093 speed: 7850 wps\n",
      "[train] 0.898 perplexity: 1.691 misclass:0.041 speed: 7853 wps\n",
      "[train] 0.998 perplexity: 1.619 misclass:0.037 speed: 7853 wps\n",
      "[test] 0.000 perplexity: 1.126 misclass:0.067 speed: 2055 wps\n",
      "[test] 0.098 perplexity: 1.101 misclass:0.067 speed: 17384 wps\n",
      "[test] 0.196 perplexity: 1.099 misclass:0.055 speed: 21542 wps\n",
      "[test] 0.294 perplexity: 1.100 misclass:0.056 speed: 23489 wps\n",
      "[test] 0.392 perplexity: 1.099 misclass:0.043 speed: 24536 wps\n",
      "[test] 0.490 perplexity: 1.096 misclass:0.053 speed: 25233 wps\n",
      "[test] 0.588 perplexity: 1.097 misclass:0.050 speed: 25679 wps\n",
      "[test] 0.686 perplexity: 1.097 misclass:0.064 speed: 26012 wps\n",
      "[test] 0.784 perplexity: 1.098 misclass:0.062 speed: 26325 wps\n",
      "[test] 0.881 perplexity: 1.097 misclass:0.069 speed: 26546 wps\n",
      "[test] 0.979 perplexity: 1.098 misclass:0.053 speed: 26734 wps\n",
      "Saving\n",
      "Epoch: 2 Learning rate: 1.000\n",
      "[train] 0.000 perplexity: 1.060 misclass:0.057 speed: 7918 wps\n",
      "[train] 0.100 perplexity: 1.094 misclass:0.047 speed: 7889 wps\n",
      "[train] 0.200 perplexity: 1.090 misclass:0.057 speed: 7888 wps\n",
      "[train] 0.299 perplexity: 1.088 misclass:0.035 speed: 7884 wps\n",
      "[train] 0.399 perplexity: 1.085 misclass:0.055 speed: 7880 wps\n",
      "[train] 0.499 perplexity: 1.083 misclass:0.034 speed: 7879 wps\n",
      "[train] 0.599 perplexity: 1.081 misclass:0.040 speed: 7875 wps\n",
      "[train] 0.699 perplexity: 1.080 misclass:0.039 speed: 7869 wps\n",
      "[train] 0.799 perplexity: 1.078 misclass:0.062 speed: 7858 wps\n",
      "[train] 0.898 perplexity: 1.077 misclass:0.037 speed: 7854 wps\n",
      "[train] 0.998 perplexity: 1.076 misclass:0.035 speed: 7852 wps\n",
      "[test] 0.000 perplexity: 1.089 misclass:0.053 speed: 7320 wps\n",
      "[test] 0.098 perplexity: 1.078 misclass:0.045 speed: 25109 wps\n",
      "[test] 0.196 perplexity: 1.076 misclass:0.046 speed: 26668 wps\n",
      "[test] 0.294 perplexity: 1.077 misclass:0.052 speed: 27221 wps\n",
      "[test] 0.392 perplexity: 1.076 misclass:0.029 speed: 27600 wps\n",
      "[test] 0.490 perplexity: 1.073 misclass:0.035 speed: 27809 wps\n",
      "[test] 0.588 perplexity: 1.074 misclass:0.038 speed: 27953 wps\n",
      "[test] 0.686 perplexity: 1.073 misclass:0.056 speed: 28077 wps\n",
      "[test] 0.784 perplexity: 1.074 misclass:0.046 speed: 28101 wps\n",
      "[test] 0.881 perplexity: 1.074 misclass:0.056 speed: 28107 wps\n",
      "[test] 0.979 perplexity: 1.074 misclass:0.051 speed: 28147 wps\n",
      "Saving\n",
      "Epoch: 3 Learning rate: 1.000\n",
      "[train] 0.000 perplexity: 1.047 misclass:0.036 speed: 7094 wps\n",
      "[train] 0.100 perplexity: 1.065 misclass:0.025 speed: 7871 wps\n",
      "[train] 0.200 perplexity: 1.063 misclass:0.024 speed: 7858 wps\n",
      "[train] 0.299 perplexity: 1.063 misclass:0.033 speed: 7851 wps\n",
      "[train] 0.399 perplexity: 1.062 misclass:0.049 speed: 7849 wps\n",
      "[train] 0.499 perplexity: 1.061 misclass:0.030 speed: 7846 wps\n",
      "[train] 0.599 perplexity: 1.061 misclass:0.047 speed: 7848 wps\n",
      "[train] 0.699 perplexity: 1.060 misclass:0.033 speed: 7845 wps\n",
      "[train] 0.799 perplexity: 1.060 misclass:0.052 speed: 7845 wps\n",
      "[train] 0.898 perplexity: 1.059 misclass:0.024 speed: 7841 wps\n",
      "[train] 0.998 perplexity: 1.059 misclass:0.033 speed: 7837 wps\n",
      "[test] 0.000 perplexity: 1.078 misclass:0.038 speed: 7592 wps\n",
      "[test] 0.098 perplexity: 1.071 misclass:0.045 speed: 25310 wps\n",
      "[test] 0.196 perplexity: 1.071 misclass:0.044 speed: 26644 wps\n",
      "[test] 0.294 perplexity: 1.072 misclass:0.048 speed: 27089 wps\n",
      "[test] 0.392 perplexity: 1.070 misclass:0.035 speed: 27415 wps\n",
      "[test] 0.490 perplexity: 1.068 misclass:0.028 speed: 27643 wps\n",
      "[test] 0.588 perplexity: 1.068 misclass:0.031 speed: 27744 wps\n",
      "[test] 0.686 perplexity: 1.067 misclass:0.053 speed: 27826 wps\n",
      "[test] 0.784 perplexity: 1.068 misclass:0.041 speed: 27913 wps\n",
      "[test] 0.881 perplexity: 1.068 misclass:0.047 speed: 27974 wps\n",
      "[test] 0.979 perplexity: 1.068 misclass:0.042 speed: 28011 wps\n",
      "Saving\n",
      "Epoch: 4 Learning rate: 1.000\n",
      "[train] 0.000 perplexity: 1.041 misclass:0.023 speed: 7688 wps\n",
      "[train] 0.100 perplexity: 1.055 misclass:0.025 speed: 7863 wps\n",
      "[train] 0.200 perplexity: 1.053 misclass:0.026 speed: 7749 wps\n",
      "[train] 0.299 perplexity: 1.053 misclass:0.031 speed: 7035 wps\n",
      "[train] 0.399 perplexity: 1.053 misclass:0.053 speed: 6935 wps\n",
      "[train] 0.499 perplexity: 1.052 misclass:0.032 speed: 6963 wps\n",
      "[train] 0.599 perplexity: 1.052 misclass:0.038 speed: 6997 wps\n",
      "[train] 0.699 perplexity: 1.052 misclass:0.029 speed: 7082 wps\n",
      "[train] 0.799 perplexity: 1.052 misclass:0.050 speed: 6929 wps\n",
      "[train] 0.898 perplexity: 1.052 misclass:0.020 speed: 6963 wps\n",
      "[train] 0.998 perplexity: 1.051 misclass:0.031 speed: 6989 wps\n",
      "[test] 0.000 perplexity: 1.075 misclass:0.042 speed: 7413 wps\n",
      "[test] 0.098 perplexity: 1.070 misclass:0.045 speed: 25238 wps\n",
      "[test] 0.196 perplexity: 1.070 misclass:0.042 speed: 26751 wps\n",
      "[test] 0.294 perplexity: 1.071 misclass:0.044 speed: 27309 wps\n",
      "[test] 0.392 perplexity: 1.069 misclass:0.027 speed: 27702 wps\n",
      "[test] 0.490 perplexity: 1.067 misclass:0.024 speed: 27709 wps\n",
      "[test] 0.588 perplexity: 1.067 misclass:0.036 speed: 27371 wps\n",
      "[test] 0.686 perplexity: 1.066 misclass:0.053 speed: 27515 wps\n",
      "[test] 0.784 perplexity: 1.067 misclass:0.041 speed: 27632 wps\n",
      "[test] 0.881 perplexity: 1.067 misclass:0.047 speed: 27710 wps\n",
      "[test] 0.979 perplexity: 1.067 misclass:0.044 speed: 27824 wps\n",
      "Saving\n",
      "Epoch: 5 Learning rate: 1.000\n",
      "[train] 0.000 perplexity: 1.036 misclass:0.023 speed: 5721 wps\n",
      "[train] 0.100 perplexity: 1.049 misclass:0.025 speed: 6708 wps\n",
      "[train] 0.200 perplexity: 1.048 misclass:0.026 speed: 7108 wps\n",
      "[train] 0.299 perplexity: 1.048 misclass:0.029 speed: 7121 wps\n",
      "[train] 0.399 perplexity: 1.048 misclass:0.045 speed: 7166 wps\n",
      "[train] 0.499 perplexity: 1.048 misclass:0.026 speed: 7208 wps\n",
      "[train] 0.599 perplexity: 1.047 misclass:0.031 speed: 7233 wps\n",
      "[train] 0.699 perplexity: 1.047 misclass:0.029 speed: 7118 wps\n",
      "[train] 0.799 perplexity: 1.047 misclass:0.052 speed: 6437 wps\n",
      "[train] 0.898 perplexity: 1.047 misclass:0.020 speed: 6005 wps\n",
      "[train] 0.998 perplexity: 1.047 misclass:0.029 speed: 5703 wps\n",
      "[test] 0.000 perplexity: 1.070 misclass:0.042 speed: 5855 wps\n",
      "[test] 0.098 perplexity: 1.068 misclass:0.049 speed: 11833 wps\n",
      "[test] 0.196 perplexity: 1.068 misclass:0.044 speed: 11683 wps\n",
      "[test] 0.294 perplexity: 1.069 misclass:0.036 speed: 12239 wps\n",
      "[test] 0.392 perplexity: 1.067 misclass:0.027 speed: 12500 wps\n",
      "[test] 0.490 perplexity: 1.065 misclass:0.026 speed: 12487 wps\n",
      "[test] 0.588 perplexity: 1.065 misclass:0.033 speed: 12523 wps\n",
      "[test] 0.686 perplexity: 1.065 misclass:0.058 speed: 12470 wps\n",
      "[test] 0.784 perplexity: 1.066 misclass:0.046 speed: 12415 wps\n",
      "[test] 0.881 perplexity: 1.066 misclass:0.049 speed: 12458 wps\n",
      "[test] 0.979 perplexity: 1.066 misclass:0.042 speed: 12576 wps\n",
      "Saving\n",
      "Epoch: 6 Learning rate: 0.500\n",
      "[train] 0.000 perplexity: 1.032 misclass:0.023 speed: 4471 wps\n",
      "[train] 0.100 perplexity: 1.043 misclass:0.027 speed: 4084 wps\n",
      "[train] 0.200 perplexity: 1.042 misclass:0.020 speed: 4144 wps\n",
      "[train] 0.299 perplexity: 1.042 misclass:0.020 speed: 4087 wps\n",
      "[train] 0.399 perplexity: 1.041 misclass:0.043 speed: 4053 wps\n",
      "[train] 0.499 perplexity: 1.041 misclass:0.024 speed: 4134 wps\n",
      "[train] 0.599 perplexity: 1.040 misclass:0.031 speed: 4171 wps\n",
      "[train] 0.699 perplexity: 1.040 misclass:0.028 speed: 4186 wps\n",
      "[train] 0.799 perplexity: 1.039 misclass:0.048 speed: 4175 wps\n",
      "[train] 0.898 perplexity: 1.039 misclass:0.022 speed: 4179 wps\n",
      "[train] 0.998 perplexity: 1.039 misclass:0.025 speed: 4208 wps\n",
      "[test] 0.000 perplexity: 1.073 misclass:0.046 speed: 5895 wps\n",
      "[test] 0.098 perplexity: 1.068 misclass:0.049 speed: 14557 wps\n",
      "[test] 0.196 perplexity: 1.067 misclass:0.036 speed: 15220 wps\n",
      "[test] 0.294 perplexity: 1.068 misclass:0.040 speed: 15434 wps\n",
      "[test] 0.392 perplexity: 1.065 misclass:0.027 speed: 15548 wps\n",
      "[test] 0.490 perplexity: 1.063 misclass:0.022 speed: 15613 wps\n",
      "[test] 0.588 perplexity: 1.063 misclass:0.038 speed: 15626 wps\n",
      "[test] 0.686 perplexity: 1.063 misclass:0.051 speed: 15677 wps\n",
      "[test] 0.784 perplexity: 1.064 misclass:0.039 speed: 15653 wps\n",
      "[test] 0.881 perplexity: 1.063 misclass:0.039 speed: 15699 wps\n",
      "[test] 0.979 perplexity: 1.064 misclass:0.036 speed: 15599 wps\n",
      "Saving\n",
      "Epoch: 7 Learning rate: 0.250\n",
      "[train] 0.000 perplexity: 1.026 misclass:0.019 speed: 4576 wps\n",
      "[train] 0.100 perplexity: 1.037 misclass:0.025 speed: 4010 wps\n",
      "[train] 0.200 perplexity: 1.036 misclass:0.018 speed: 4214 wps\n",
      "[train] 0.299 perplexity: 1.036 misclass:0.018 speed: 4217 wps\n",
      "[train] 0.399 perplexity: 1.036 misclass:0.041 speed: 4248 wps\n",
      "[train] 0.499 perplexity: 1.035 misclass:0.028 speed: 4278 wps\n",
      "[train] 0.599 perplexity: 1.035 misclass:0.029 speed: 4308 wps\n",
      "[train] 0.699 perplexity: 1.035 misclass:0.026 speed: 4290 wps\n",
      "[train] 0.799 perplexity: 1.034 misclass:0.044 speed: 4487 wps\n",
      "[train] 0.898 perplexity: 1.034 misclass:0.015 speed: 4709 wps\n",
      "[train] 0.998 perplexity: 1.033 misclass:0.023 speed: 4895 wps\n",
      "[test] 0.000 perplexity: 1.072 misclass:0.049 speed: 7308 wps\n",
      "[test] 0.098 perplexity: 1.069 misclass:0.047 speed: 24936 wps\n",
      "[test] 0.196 perplexity: 1.068 misclass:0.029 speed: 26516 wps\n",
      "[test] 0.294 perplexity: 1.068 misclass:0.040 speed: 26936 wps\n",
      "[test] 0.392 perplexity: 1.066 misclass:0.027 speed: 27119 wps\n",
      "[test] 0.490 perplexity: 1.063 misclass:0.024 speed: 27244 wps\n",
      "[test] 0.588 perplexity: 1.064 misclass:0.039 speed: 27274 wps\n",
      "[test] 0.686 perplexity: 1.063 misclass:0.053 speed: 27271 wps\n",
      "[test] 0.784 perplexity: 1.064 misclass:0.039 speed: 27309 wps\n",
      "[test] 0.881 perplexity: 1.064 misclass:0.032 speed: 27425 wps\n",
      "[test] 0.979 perplexity: 1.064 misclass:0.038 speed: 27484 wps\n",
      "Saving\n",
      "Epoch: 8 Learning rate: 0.125\n",
      "[train] 0.000 perplexity: 1.023 misclass:0.019 speed: 4884 wps\n",
      "[train] 0.100 perplexity: 1.034 misclass:0.019 speed: 7299 wps\n",
      "[train] 0.200 perplexity: 1.033 misclass:0.016 speed: 7307 wps\n",
      "[train] 0.299 perplexity: 1.033 misclass:0.018 speed: 7408 wps\n",
      "[train] 0.399 perplexity: 1.032 misclass:0.041 speed: 7439 wps\n",
      "[train] 0.499 perplexity: 1.032 misclass:0.024 speed: 7430 wps\n",
      "[train] 0.599 perplexity: 1.032 misclass:0.025 speed: 7383 wps\n",
      "[train] 0.699 perplexity: 1.031 misclass:0.025 speed: 7384 wps\n",
      "[train] 0.799 perplexity: 1.031 misclass:0.035 speed: 7259 wps\n",
      "[train] 0.898 perplexity: 1.031 misclass:0.015 speed: 7270 wps\n",
      "[train] 0.998 perplexity: 1.030 misclass:0.023 speed: 7288 wps\n",
      "[test] 0.000 perplexity: 1.073 misclass:0.051 speed: 7286 wps\n",
      "[test] 0.098 perplexity: 1.070 misclass:0.041 speed: 24001 wps\n",
      "[test] 0.196 perplexity: 1.069 misclass:0.032 speed: 25801 wps\n",
      "[test] 0.294 perplexity: 1.069 misclass:0.042 speed: 26442 wps\n",
      "[test] 0.392 perplexity: 1.066 misclass:0.027 speed: 26589 wps\n",
      "[test] 0.490 perplexity: 1.064 misclass:0.022 speed: 26950 wps\n",
      "[test] 0.588 perplexity: 1.064 misclass:0.038 speed: 27208 wps\n",
      "[test] 0.686 perplexity: 1.064 misclass:0.053 speed: 27341 wps\n",
      "[test] 0.784 perplexity: 1.065 misclass:0.034 speed: 27302 wps\n",
      "[test] 0.881 perplexity: 1.064 misclass:0.032 speed: 27040 wps\n",
      "[test] 0.979 perplexity: 1.064 misclass:0.036 speed: 26427 wps\n",
      "Saving\n",
      "Epoch: 9 Learning rate: 0.062\n",
      "[train] 0.000 perplexity: 1.022 misclass:0.017 speed: 7450 wps\n",
      "[train] 0.100 perplexity: 1.031 misclass:0.017 speed: 7661 wps\n",
      "[train] 0.200 perplexity: 1.031 misclass:0.018 speed: 7665 wps\n",
      "[train] 0.299 perplexity: 1.031 misclass:0.015 speed: 7650 wps\n",
      "[train] 0.399 perplexity: 1.030 misclass:0.039 speed: 7548 wps\n",
      "[train] 0.499 perplexity: 1.030 misclass:0.023 speed: 7488 wps\n",
      "[train] 0.599 perplexity: 1.030 misclass:0.027 speed: 7430 wps\n",
      "[train] 0.699 perplexity: 1.030 misclass:0.023 speed: 7470 wps\n",
      "[train] 0.799 perplexity: 1.029 misclass:0.035 speed: 7366 wps\n",
      "[train] 0.898 perplexity: 1.029 misclass:0.013 speed: 7211 wps\n",
      "[train] 0.998 perplexity: 1.028 misclass:0.018 speed: 7206 wps\n",
      "[test] 0.000 perplexity: 1.073 misclass:0.051 speed: 7315 wps\n",
      "[test] 0.098 perplexity: 1.070 misclass:0.045 speed: 24555 wps\n",
      "[test] 0.196 perplexity: 1.069 misclass:0.034 speed: 26325 wps\n",
      "[test] 0.294 perplexity: 1.069 misclass:0.042 speed: 26896 wps\n",
      "[test] 0.392 perplexity: 1.067 misclass:0.025 speed: 27075 wps\n",
      "[test] 0.490 perplexity: 1.064 misclass:0.024 speed: 27003 wps\n",
      "[test] 0.588 perplexity: 1.064 misclass:0.036 speed: 27165 wps\n",
      "[test] 0.686 perplexity: 1.064 misclass:0.053 speed: 27247 wps\n",
      "[test] 0.784 perplexity: 1.065 misclass:0.037 speed: 27238 wps\n",
      "[test] 0.881 perplexity: 1.064 misclass:0.030 speed: 27377 wps\n",
      "[test] 0.979 perplexity: 1.065 misclass:0.036 speed: 27285 wps\n",
      "Saving\n",
      "Epoch: 10 Learning rate: 0.031\n",
      "[train] 0.000 perplexity: 1.020 misclass:0.019 speed: 7753 wps\n",
      "[train] 0.100 perplexity: 1.030 misclass:0.016 speed: 7201 wps\n",
      "[train] 0.200 perplexity: 1.030 misclass:0.016 speed: 7321 wps\n",
      "[train] 0.299 perplexity: 1.030 misclass:0.018 speed: 7260 wps\n",
      "[train] 0.399 perplexity: 1.029 misclass:0.037 speed: 7319 wps\n",
      "[train] 0.499 perplexity: 1.029 misclass:0.021 speed: 7304 wps\n",
      "[train] 0.599 perplexity: 1.029 misclass:0.027 speed: 7278 wps\n",
      "[train] 0.699 perplexity: 1.029 misclass:0.023 speed: 7305 wps\n",
      "[train] 0.799 perplexity: 1.028 misclass:0.031 speed: 7325 wps\n",
      "[train] 0.898 perplexity: 1.028 misclass:0.013 speed: 7351 wps\n",
      "[train] 0.998 perplexity: 1.027 misclass:0.018 speed: 7350 wps\n",
      "[test] 0.000 perplexity: 1.073 misclass:0.051 speed: 7636 wps\n",
      "[test] 0.098 perplexity: 1.070 misclass:0.045 speed: 24717 wps\n",
      "[test] 0.196 perplexity: 1.069 misclass:0.036 speed: 26122 wps\n",
      "[test] 0.294 perplexity: 1.069 misclass:0.040 speed: 26648 wps\n",
      "[test] 0.392 perplexity: 1.067 misclass:0.027 speed: 26311 wps\n",
      "[test] 0.490 perplexity: 1.064 misclass:0.022 speed: 25776 wps\n",
      "[test] 0.588 perplexity: 1.064 misclass:0.038 speed: 25694 wps\n",
      "[test] 0.686 perplexity: 1.064 misclass:0.051 speed: 25628 wps\n",
      "[test] 0.784 perplexity: 1.065 misclass:0.039 speed: 25791 wps\n",
      "[test] 0.881 perplexity: 1.065 misclass:0.030 speed: 26011 wps\n",
      "[test] 0.979 perplexity: 1.065 misclass:0.036 speed: 26214 wps\n",
      "Saving\n"
     ]
    }
   ],
   "source": [
    "best_misclass = 1.0\n",
    "\n",
    "for i in range(10):\n",
    "    lr_decay = 0.5 ** max(i - 4, 0.0)\n",
    "    assign_lr(sess, 1.0 * lr_decay)\n",
    "\n",
    "    print(\"Epoch: %d Learning rate: %.3f\" % (i + 1, sess.run(lr)))\n",
    "    train_perplexity, _ = run_epoch(X_train, Y_train, mask_train,\n",
    "                                    train_op, verbose=True)\n",
    "    _, misclassifications = run_epoch(X_test, Y_test, mask_test,\n",
    "                            tf.no_op(), training=False, verbose=True)\n",
    "    if misclassifications < best_misclass:\n",
    "        best_misclass = misclassifications\n",
    "        saver.save(sess, './data/bid3rnn_tagger.ckpt', global_step=i)\n",
    "        print('Saving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model restored!\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, \"./data/bid3rnn_tagger.ckpt-9\")\n",
    "print(\"Best model restored!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smothered_logits = tf.boolean_mask(logits, tf.reshape(mask, [-1]))\n",
    "smothered_targets = tf.reshape(tf.boolean_mask(targets, mask), [-1])\n",
    "\n",
    "s = tf.nn.softmax(smothered_logits)\n",
    "s_prob = tf.reduce_max(s, reduction_indices=[1], keep_dims=True)\n",
    "kl_all = tf.log(len(reader.tag_to_id)*1.) + tf.reduce_sum(s * tf.log(tf.abs(s) + 1e-10),\n",
    "                                                          reduction_indices=[1], keep_dims=True)\n",
    "m_all, v_all = tf.nn.moments(kl_all, axes=[0])\n",
    "\n",
    "logits_right = tf.boolean_mask(smothered_logits,\n",
    "                               tf.equal(tf.argmax(smothered_logits, 1), smothered_targets))\n",
    "s_right = tf.nn.softmax(logits_right)\n",
    "s_right_prob = tf.reduce_max(s_right, reduction_indices=[1], keep_dims=True)\n",
    "kl_right = tf.log(len(reader.tag_to_id)*1.) + tf.reduce_sum(s_right * tf.log(tf.abs(s_right) + 1e-10),\n",
    "                                                            reduction_indices=[1], keep_dims=True)\n",
    "m_right, v_right = tf.nn.moments(kl_right, axes=[0])\n",
    "\n",
    "logits_wrong = tf.boolean_mask(smothered_logits,\n",
    "                               tf.not_equal(tf.argmax(smothered_logits, 1), smothered_targets))\n",
    "s_wrong = tf.nn.softmax(logits_wrong)\n",
    "s_wrong_prob = tf.reduce_max(s_wrong, reduction_indices=[1], keep_dims=True)\n",
    "kl_wrong = tf.log(len(reader.tag_to_id)*1.) + tf.reduce_sum(s_wrong * tf.log(tf.abs(s_wrong) + 1e-10),\n",
    "                                                            reduction_indices=[1], keep_dims=True)\n",
    "m_wrong, v_wrong = tf.nn.moments(kl_wrong, axes=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSJ Error (%)| Prediction Prob (mean, std) | PProb Right (mean, std) | PProb Wrong (mean, std):\n",
      "3.68122 | 0.976156 0.0895798 | 0.986341 0.0628749 | 0.709671 0.202042\n",
      "\n",
      "Success Detection\n",
      "Success base rate (%): 96.32\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 99.8\n",
      "AUROC (%): 95.92\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 99.8\n",
      "AUROC (%): 95.93\n",
      "\n",
      "Error Detection\n",
      "Error base rate (%): 3.68\n",
      "KL[p||u]: Right/Wrong classification distinction\n",
      "AUPR (%): 50.4\n",
      "AUROC (%): 95.92\n",
      "Prediction Prob: Right/Wrong classification distinction\n",
      "AUPR (%): 50.9\n",
      "AUROC (%): 95.93\n"
     ]
    }
   ],
   "source": [
    "err, kl_a, kl_r, kl_w, s_p, s_rp, s_wp = sess.run(\n",
    "    [100*misclass, kl_all, kl_right, kl_wrong, s_prob, s_right_prob, s_wrong_prob],\n",
    "    feed_dict={input_data: X_test, targets: Y_test, mask: mask_test})\n",
    "\n",
    "print('WSJ Error (%)| Prediction Prob (mean, std) | PProb Right (mean, std) | PProb Wrong (mean, std):')\n",
    "print(err, '|', np.mean(s_p), np.std(s_p), '|', np.mean(s_rp), np.std(s_rp), '|', np.mean(s_wp), np.std(s_wp))\n",
    "\n",
    "print('\\nSuccess Detection')\n",
    "print('Success base rate (%):', round(100-err,2))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "safe, risky = kl_r, kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = s_rp, s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[:safe.shape[0]] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "print('\\nError Detection')\n",
    "print('Error base rate (%):', round(err,2))\n",
    "safe, risky = -kl_r, -kl_w\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('KL[p||u]: Right/Wrong classification distinction')\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "print('Prediction Prob: Right/Wrong classification distinction')\n",
    "safe, risky = -s_rp, -s_wp\n",
    "labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "labels[safe.shape[0]:] += 1\n",
    "examples = np.squeeze(np.vstack((safe, risky)))\n",
    "print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_ood_detection_results(error_rate_for_in, in_examples, out_examples, out_mask):\n",
    "    kl_oos, s_p_oos = sess.run([kl_all, s_prob], feed_dict={input_data: out_examples, mask: out_mask})\n",
    "\n",
    "    print('OOD Example Prediction Probability (mean, std):')\n",
    "    print(np.mean(s_p_oos), np.std(s_p_oos))\n",
    "\n",
    "    print('\\nNormality Detection')\n",
    "    print('Normality base rate (%):', round(100*in_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection')\n",
    "    safe, risky = kl_a, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection')\n",
    "    safe, risky = s_p, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Normality base rate (%):', round(100*(1 - err/100)*in_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = kl_r, kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Normality Detection (relative to correct examples)')\n",
    "    safe, risky = s_rp, s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[:safe.shape[0]] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "\n",
    "    print('\\n\\nAbnormality Detection')\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/(\n",
    "                out_examples.shape[0] + in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Abnormality Detection')\n",
    "    safe, risky = -kl_a, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Abnormality Detection')\n",
    "    safe, risky = -s_p, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Abnormality base rate (%):', round(100*out_examples.shape[0]/\n",
    "          (out_examples.shape[0] + (1 - err/100)*in_examples.shape[0]),2))\n",
    "    print('KL[p||u]: Abnormality Detection (relative to correct examples)')\n",
    "    safe, risky = -kl_r, -kl_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))\n",
    "\n",
    "    print('Prediction Prob: Abnormality Detection (relative to correct examples)')\n",
    "    safe, risky = -s_rp, -s_p_oos\n",
    "    labels = np.zeros((safe.shape[0] + risky.shape[0]), dtype=np.int32)\n",
    "    labels[safe.shape[0]:] += 1\n",
    "    examples = np.squeeze(np.vstack((safe, risky)))\n",
    "    print('AUPR (%):', round(100*sk.average_precision_score(labels, examples), 2))\n",
    "    print('AUROC (%):', round(100*sk.roc_auc_score(labels, examples), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reader.tag_to_id   # determine START, END, and PAD symbols from this; it's 0, 15, 16 in this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mask_for_data(_dataset, to_ignore=[0,15,16]):\n",
    "    _mask = np.ones(_dataset.shape, dtype=np.bool)\n",
    "    for tag_to_ignore in to_ignore:\n",
    "        _mask = np.logical_and(_mask, _dataset != tag_to_ignore)\n",
    "    return _mask\n",
    "\n",
    "vocab = reader.word_to_id.keys()\n",
    "\n",
    "# we replace <s> with </s> since it has no embedding, and </s> is a better embedding than UNK\n",
    "xt, yt = data_to_mat('./data/Tweets/tweets-train.txt', vocab, reader.word_to_id,\n",
    "                     start_tag=0, end_tag=15, pad_tag=16)\n",
    "xdev, ydev = data_to_mat('./data/Tweets/tweets-dev.txt', vocab, reader.word_to_id,\n",
    "                         start_tag=0, end_tag=15, pad_tag=16)\n",
    "xdtest, ydtest = data_to_mat('./data/Tweets/tweets-devtest.txt', vocab, reader.word_to_id,\n",
    "                             start_tag=0, end_tag=15, pad_tag=16)\n",
    "\n",
    "tweets = {\n",
    "    'x_train': xt, 'y_train': yt, 'train_mask': mask_for_data(yt),\n",
    "    'x_dev': xdev, 'y_dev': ydev, 'dev_mask': mask_for_data(ydev),\n",
    "    'x_devtest': xdtest, 'y_devtest': ydtest, 'devtest_mask': mask_for_data(ydtest),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Twitter OOD Detection\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.80984 0.248264\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 92.58\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 97.62\n",
      "AUROC (%): 78.17\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 97.6\n",
      "AUROC (%): 77.79\n",
      "Normality base rate (%): 92.32\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 97.7\n",
      "AUROC (%): 79.8\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 97.68\n",
      "AUROC (%): 79.54\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 7.42\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 35.43\n",
      "AUROC (%): 78.17\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 31.14\n",
      "AUROC (%): 77.79\n",
      "Abnormality base rate (%): 7.68\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 44.27\n",
      "AUROC (%): 79.8\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 40.8\n",
      "AUROC (%): 79.54\n"
     ]
    }
   ],
   "source": [
    "print('Twitter OOD Detection\\n')\n",
    "show_ood_detection_results(err, X_test, tweets['x_devtest'], tweets['devtest_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English Web Treebanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtest, ytest = data_to_mat('./data/WebTreeBank/weblog_penntrees.test.conll', vocab,\n",
    "                           reader.word_to_id, is_not_twitter=True, start_tag=0, end_tag=15, pad_tag=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webblog OOD Detection\n",
      "\n",
      "OOD Example Prediction Probability (mean, std):\n",
      "0.933841 0.15627\n",
      "\n",
      "Normality Detection\n",
      "Normality base rate (%): 86.01\n",
      "KL[p||u]: Normality Detection\n",
      "AUPR (%): 87.88\n",
      "AUROC (%): 59.84\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 87.84\n",
      "AUROC (%): 59.7\n",
      "Normality base rate (%): 85.55\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 87.94\n",
      "AUROC (%): 61.6\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 87.91\n",
      "AUROC (%): 61.48\n",
      "\n",
      "\n",
      "Abnormality Detection\n",
      "Abnormality base rate (%): 13.99\n",
      "KL[p||u]: Abnormality Detection\n",
      "AUPR (%): 24.98\n",
      "AUROC (%): 59.84\n",
      "Prediction Prob: Normality Detection\n",
      "AUPR (%): 23.91\n",
      "AUROC (%): 59.7\n",
      "Abnormality base rate (%): 14.45\n",
      "KL[p||u]: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 30.57\n",
      "AUROC (%): 61.6\n",
      "Prediction Prob: Normality Detection (relative to correct examples)\n",
      "AUPR (%): 29.52\n",
      "AUROC (%): 61.48\n"
     ]
    }
   ],
   "source": [
    "print('Webblog OOD Detection\\n')\n",
    "show_ood_detection_results(err, X_test, xtest, mask_for_data(ytest))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

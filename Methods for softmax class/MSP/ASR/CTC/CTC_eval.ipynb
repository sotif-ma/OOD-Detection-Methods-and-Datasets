{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.ops import ctc_ops as ctc\n",
    "from tensorflow.contrib.ctc import ctc_ops as ctc   # depreciated in future\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from utils import load_batched_data, target_list_to_sparse_tensor\n",
    "import pickle\n",
    "import sklearn.metrics as sk\n",
    "\n",
    "####Learning Parameters\n",
    "nEpochs = 60\n",
    "batchSize = 100\n",
    "\n",
    "####Network Parameters\n",
    "nFeatures = 39      # MFCC coefficients, energy, delta, delta delta\n",
    "nHidden = 256\n",
    "nClasses = 40       # 40 because of 39 phones, plus the \"blank\" for CTC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "####Load data\n",
    "print('Loading data')\n",
    "data = pickle.load(open(\"TIMIT_data_prepared_for_CTC_clean.pkl\", 'rb'), encoding='latin1')\n",
    "\n",
    "# 6300 x 776 x 39\n",
    "\n",
    "# we will the last 1300 examples from the 6300\n",
    "data_list = []\n",
    "for i in range(1300//batchSize):\n",
    "    offset = 5000 + batchSize * i\n",
    "    target_list = []\n",
    "    for j in range(batchSize):\n",
    "        target_list.append(data['y_phones'][offset+j])\n",
    "    data_list.append(\n",
    "        (data['x'][offset:offset+batchSize,:,:],\n",
    "         target_list_to_sparse_tensor(target_list),\n",
    "         data['mask'][offset:offset+batchSize]))\n",
    "\n",
    "del data\n",
    "\n",
    "batchedData, maxTimeSteps, totalN = data_list, 776, 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining graph\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clipped_gelu(x):\n",
    "    return tf.minimum(0.5 * x * (1 + tf.tanh(x)), 6)\n",
    "\n",
    "####Define graph\n",
    "print('Defining graph')\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    ####NOTE: try variable-steps inputs and dynamic bidirectional rnn, when it's implemented in tensorflow\n",
    "\n",
    "    ####Graph input\n",
    "    inputX = tf.placeholder(tf.float32, shape=(batchSize, maxTimeSteps, nFeatures))\n",
    "\n",
    "    #Prep input data to fit requirements of rnn.bidirectional_rnn\n",
    "    #  Reshape to 2-D tensor (nTimeSteps*batchSize, nfeatures)\n",
    "    inputXrs = tf.reshape(tf.transpose(inputX, [1, 0, 2]), [-1, nFeatures])\n",
    "    #  Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "    inputList = tf.split(0, maxTimeSteps, inputXrs)\n",
    "    targetIxs = tf.placeholder(tf.int64)\n",
    "    targetVals = tf.placeholder(tf.int32)\n",
    "    targetShape = tf.placeholder(tf.int64)\n",
    "    targetY = tf.SparseTensor(targetIxs, targetVals, targetShape)\n",
    "    seqLengths = tf.placeholder(tf.int32, shape=(batchSize))\n",
    "    # print(inputX, targetIxs, targetVals, targetShape, seqLengths)\n",
    "\n",
    "    ####Weights & biases\n",
    "    weightsOutH1 = tf.Variable(tf.truncated_normal([2, nHidden],\n",
    "                                                   stddev=np.sqrt(2.0 / (2*nHidden))))\n",
    "    biasesOutH1 = tf.Variable(tf.zeros([nHidden]))\n",
    "    weightsOutH2 = tf.Variable(tf.truncated_normal([2, nHidden],\n",
    "                                                   stddev=np.sqrt(2.0 / (2*nHidden))))\n",
    "    biasesOutH2 = tf.Variable(tf.zeros([nHidden]))\n",
    "    weightsClasses = tf.Variable(tf.truncated_normal([nHidden, nClasses],\n",
    "                                                     stddev=np.sqrt(2.0 / nHidden)))\n",
    "    biasesClasses = tf.Variable(tf.zeros([nClasses]))\n",
    "\n",
    "    ####Network\n",
    "    lstm_cell = tf.nn.rnn_cell.LSTMCell(nHidden, state_is_tuple=True, activation=clipped_gelu)\n",
    "\n",
    "    cell_fw = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * 2, state_is_tuple=True)\n",
    "    cell_bw = tf.nn.rnn_cell.MultiRNNCell([lstm_cell] * 2, state_is_tuple=True)\n",
    "\n",
    "    fbH1, _, _ = tf.nn.bidirectional_rnn(cell_fw, cell_bw, inputList, dtype=tf.float32,\n",
    "                                         scope='BDLSTM_H1')\n",
    "    fbH1rs = [tf.reshape(t, [batchSize, 2, nHidden]) for t in fbH1]\n",
    "    outH1 = [tf.reduce_sum(tf.mul(t, weightsOutH1), reduction_indices=1) + biasesOutH1 for t in fbH1rs]\n",
    "\n",
    "    logits = [tf.matmul(t, weightsClasses) + biasesClasses for t in outH1]\n",
    "\n",
    "    ####Optimizing\n",
    "    logits3d = tf.pack(logits)\n",
    "    loss = tf.reduce_mean(ctc.ctc_loss(logits3d, targetY, seqLengths))\n",
    "\n",
    "    lr = tf.Variable(0.005, trainable=False)\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), 5)\n",
    "    opt = tf.train.RMSPropOptimizer(lr)\n",
    "    optimizer = opt.apply_gradients(zip(grads, tvars))\n",
    "\n",
    "    ####Evaluating\n",
    "    predictions = tf.to_int32(ctc.ctc_beam_search_decoder(logits3d, seqLengths)[0][0])\n",
    "    errorRate = tf.reduce_sum(tf.edit_distance(predictions, targetY, normalize=False)) / \\\n",
    "                tf.to_float(tf.size(targetY.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Restored\n"
     ]
    }
   ],
   "source": [
    "session = tf.InteractiveSession(graph=graph)\n",
    "tf.initialize_all_variables().run()\n",
    "saver = tf.train.Saver(max_to_keep=1)\n",
    "saver.restore(session, \"./bdlstm-timit-clean.ckpt\")\n",
    "print('Model Restored')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edit distance 30.6003322968 Softmax Confidence (mean, std) 0.674199 0.0284798\n"
     ]
    }
   ],
   "source": [
    "kl_all = []\n",
    "pred_all = []\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "batchErrors = np.zeros(len(batchedData))\n",
    "batchRandIxs = np.random.permutation(len(batchedData))      # randomize batch order\n",
    "for batch, batchOrigI in enumerate(batchRandIxs):\n",
    "    batchInputs, batchTargetSparse, batchSeqLengths = batchedData[batchOrigI]\n",
    "    batchTargetIxs, batchTargetVals, batchTargetShape = batchTargetSparse\n",
    "    feedDict = {inputX: batchInputs, targetIxs: batchTargetIxs, targetVals: batchTargetVals.tolist(),\n",
    "                targetShape: batchTargetShape, seqLengths: batchSeqLengths}\n",
    "    er, preds = session.run([errorRate, logits3d], feed_dict=feedDict)\n",
    "\n",
    "    for i in range(preds.shape[1]):\n",
    "        preds_cut_by_time = preds[:int(batchSeqLengths[i]), i, :]\n",
    "        # remove example where blank is predicted\n",
    "        #preds_blanks_removed = preds_cut_by_time[np.not_equal(np.argmax(preds_cut_by_time, 1), 39)]\n",
    "        #s_pred_blanks_removed = softmax(preds_blanks_removed[:,:39]) # remove the blank\n",
    "        s_pred_blanks_removed = softmax(preds_cut_by_time[:,:39]) # remove the blank\n",
    "        \n",
    "        kl = np.mean(np.log(nFeatures-1) + np.sum(s_pred_blanks_removed * np.log(s_pred_blanks_removed + 1e-11), axis=1))\n",
    "\n",
    "        kl_all.append(kl)\n",
    "        pred_all.append(np.mean(np.max(s_pred_blanks_removed, axis=1)))\n",
    "\n",
    "    batchErrors[batch] = er*len(batchSeqLengths)\n",
    "epochErrorRate = batchErrors.sum() / len(batchedData)\n",
    "\n",
    "print('Edit distance', epochErrorRate, 'Softmax Confidence (mean, std)', np.mean(pred_all), np.std(pred_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del data_list; del batchedData; del batch # save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OOD data\n",
      "subway edit distance 83.853751421 Softmax Confidence (mean, std) 0.561752 0.025822\n",
      "\n",
      "subway KL[p||u]: In/out distribution distinction\n",
      "AUPR 0.999231995538\n",
      "AUROC 0.999072189349\n",
      "\n",
      "subway Prediction Prob: In/out distribution distinction\n",
      "AUPR 0.998823015241\n",
      "AUROC 0.998792899408\n"
     ]
    }
   ],
   "source": [
    "for oos_name in ['subway']:# ['airport', 'babble', 'car', 'exhibition', 'restaurant', 'street', 'subway', 'train']:\n",
    "    print('Loading OOD data')\n",
    "    data = pickle.load(open(\"TIMIT_data_prepared_for_CTC_\" + oos_name + \".pkl\", 'rb'), encoding='latin1')\n",
    "\n",
    "    # 6300 x 776 x 39\n",
    "\n",
    "    # we will the last 1300 examples from the 6300\n",
    "    data_list = []\n",
    "    for i in range(1300//batchSize):\n",
    "        offset = 5000 + batchSize * i\n",
    "        target_list = []\n",
    "        for j in range(batchSize):\n",
    "            target_list.append(data['y_phones'][offset+j])\n",
    "        data_list.append(\n",
    "            (data['x'][offset:offset+batchSize,:,:],\n",
    "             target_list_to_sparse_tensor(target_list),\n",
    "             data['mask'][offset:offset+batchSize]))\n",
    "\n",
    "    del data\n",
    "\n",
    "    batchedData, maxTimeSteps, totalN = data_list, 776, 13\n",
    "\n",
    "    kl_ood = []\n",
    "    pred_ood = []\n",
    "\n",
    "    def softmax(x):\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "    batchErrors = np.zeros(len(batchedData))\n",
    "    batchRandIxs = np.random.permutation(len(batchedData))      # randomize batch order\n",
    "    for batch, batchOrigI in enumerate(batchRandIxs):\n",
    "        batchInputs, batchTargetSparse, batchSeqLengths = batchedData[batchOrigI]\n",
    "        batchTargetIxs, batchTargetVals, batchTargetShape = batchTargetSparse\n",
    "        feedDict = {inputX: batchInputs, targetIxs: batchTargetIxs, targetVals: batchTargetVals.tolist(),\n",
    "                    targetShape: batchTargetShape, seqLengths: batchSeqLengths}\n",
    "        er, preds = session.run([errorRate, logits3d], feed_dict=feedDict)\n",
    "\n",
    "        for i in range(preds.shape[1]):\n",
    "            preds_cut_by_time = preds[:int(batchSeqLengths[i]), i, :]\n",
    "            # remove example where blank is predicted\n",
    "            # preds_blanks_removed = preds_cut_by_time[np.not_equal(np.argmax(preds_cut_by_time, 1), 39)]\n",
    "            s_pred_blanks_removed = softmax(preds_cut_by_time[:,:39])\n",
    "\n",
    "            kl = np.mean(np.log(nFeatures-1) + np.sum(s_pred_blanks_removed * np.log(s_pred_blanks_removed + 1e-11), axis=1))\n",
    "\n",
    "            kl_ood.append(kl)\n",
    "            pred_ood.append(np.mean(np.max(s_pred_blanks_removed, axis=1)))\n",
    "\n",
    "        batchErrors[batch] = er*len(batchSeqLengths)\n",
    "    epochErrorRate = batchErrors.sum() / len(batchedData)\n",
    "\n",
    "    print(oos_name, 'edit distance', epochErrorRate, 'Softmax Confidence (mean, std)', np.mean(pred_ood), np.std(pred_ood))\n",
    "\n",
    "    print('\\n'+ oos_name, 'KL[p||u]: In/out distribution distinction')\n",
    "    in_sample, oos = kl_all, kl_ood\n",
    "    labels = np.zeros((len(in_sample) + len(oos)), dtype=np.int32)\n",
    "    labels[:len(in_sample)] += 1\n",
    "    examples = np.squeeze(np.vstack((np.array(in_sample).reshape((-1,1)), np.array(oos).reshape((-1,1)))))\n",
    "    print('AUPR', sk.average_precision_score(labels, examples))\n",
    "    print('AUROC', sk.roc_auc_score(labels, examples))\n",
    "\n",
    "    print('\\n'+ oos_name, 'Prediction Prob: In/out distribution distinction')\n",
    "    in_sample, oos = pred_all, pred_ood\n",
    "    labels = np.zeros((len(in_sample) + len(oos)), dtype=np.int32)\n",
    "    labels[:len(in_sample)] += 1\n",
    "    examples = np.squeeze(np.vstack((np.array(in_sample).reshape((-1,1)), np.array(oos).reshape((-1,1)))))\n",
    "    print('AUPR', sk.average_precision_score(labels, examples))\n",
    "    print('AUROC', sk.roc_auc_score(labels, examples))\n",
    "\n",
    "    del data_list; del batchedData; del batch   # save memory; it's possible that this doesn't work at all\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
